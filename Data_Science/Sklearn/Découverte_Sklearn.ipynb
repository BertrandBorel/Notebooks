{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e90dd6",
   "metadata": {},
   "source": [
    "# <center> Découverte de Scikit-learn </center>\n",
    "\n",
    "**Source :**  MASSARON L., MUELLER J.-P., Data science avec Python pour les nuls, First, 2019, p.232-299.\n",
    "    \n",
    "## Les classes de Scikit-learn\n",
    "\n",
    "La classe ancestrale `BaseEstimator` est la mère de toutes les autres. Quatre classes couvrent toutes les possibilités d'apprentissage machine de base :\n",
    "- Classification\n",
    "- Régression\n",
    "- Regroupement en groupes (clusters)\n",
    "- Transformations\n",
    "Chaque classe de base définit ses propres méthodes et attributs. \n",
    "\n",
    "Interfaces (API) orientées objets de Sklearn : garantissent l'homogénéité des méthodes et attributs entre les différents algorithmes du paquetage. Ils sont au nombre de 4 :\n",
    "- `estimator`: pour ajuster les paramètres en les apprenants à partir des données grâce à l'algorithme\n",
    "- `predicator`: pour générer des prédictions à partir des paramètres ajustés\n",
    "- `transformator`: pour transformer des données en utilisant les paramètres ajustés \n",
    "- `model`: pour rendre compte de la qualité d'ajustement ou d'autres points de mesure.\n",
    "\n",
    "## Sélection d'applications pour la datalogie\n",
    "\n",
    "L'interface `estimator` règle les problèmes suivants :\n",
    "- **problèmes de classification :** pour estimer qu'une nouvelle observation appartient ou non à un certain groupe.\n",
    "- **problèmes de régression :** pour estimer la valeur d'une nouvelle observation.\n",
    "\n",
    "Dans ce cas précis, il s'agit d'appliquer la méthode `fit(X, y)`, `X` correspondant au tableau bidimensionnel de prédicteurs (donc le jeu d'observation à apprendre) alors que `y` est le résultat, soit un tableau à 1 dimension.\n",
    "\n",
    "En appliquant la méthode `fit()`, vous mettez en relation l'information dans `X` avec `y`. Une nouvelle donnée ayant les mêmes caractéristiques que `X` permet de déduire `y`correctement. Certains des paramètres sont estimés par la méthode `fit()` en interne. Vous pouvez ainsi distinguer les paramètres qui sont appris des hyperparamètres qui sont définis par vous au moment de créer l'instance de l'apprenant. \n",
    "\n",
    "Cette instanciation consiste à associer une classe de Sklearn à une variable Python. En plus des hyperparamètres, vous pouvez stimuler des paramètres de travail, par exemple la normalisation demandée ou la semence des valeurs aléatoires afin d'obtenir les mêmes résultats dans tous les appels travaillant sur les mêmes données d'entrée. \n",
    "\n",
    "## Exemple de régression linéaire\n",
    "\n",
    "Le dataset Boston contient des variables prédicateurs que nous pouvons confronter aux prix des maisons, afin de générer un prédicateur qui va pouvoir estimer une nouvelle maison à partir de ses caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57f5997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(506, 13) y:(506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "print(\"X:%s y:%s\" %(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc6f2a",
   "metadata": {},
   "source": [
    "Les 2 tableaux ont le même nombre de lignes et `X` comporte 13 caractéristiques. La méthode `shape()` analyse un tableau et renvoie sa dimension.\n",
    "Le nombre de lignes doit être le même pour `X`et `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d397c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.08011358e-01  4.64204584e-02  2.05586264e-02  2.68673382e+00\n",
      " -1.77666112e+01  3.80986521e+00  6.92224640e-04 -1.47556685e+00\n",
      "  3.06049479e-01 -1.23345939e-02 -9.52747232e-01  9.31168327e-03\n",
      " -5.24758378e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utilisateur\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# importation de la classe LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instanciation d'une variable + choix du mode de normalisation\n",
    "hypothesis = LinearRegression(normalize=True)\n",
    "\n",
    "# ajustement = la variable contient les paramètres appris\n",
    "hypothesis.fit(X, y)\n",
    "\n",
    "# affichage des coefficients\n",
    "print(hypothesis.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d063d8c",
   "metadata": {},
   "source": [
    "Une hypothèse est une façon de décrire un algorithme qui a été entraîné avec des données. L'hypothèse définit une représentation possible de **y** en fonction de **X** que vous testez au niveau de la validité. C'est donc une hypothèse tant en termes scientifiques, qu'en termes d'apprentissage machine.\n",
    "\n",
    "### Prédicteur :\n",
    "\n",
    "La classe `predictor` sert à prédire la probabilité d'un certain résultat, en obtenant ce résultat pour les nouvelles observations avec ses méthodes `predict()` et `predict_proba()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beae254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.90156732]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "new_observation = np.array([1, 0, 1, 0, 0.5, 7, 59,\n",
    "                           6, 3, 200, 20, 350, 4],\n",
    "                          dtype=float).reshape(1, -1)\n",
    "\n",
    "# predict\n",
    "print(hypothesis.predict(new_observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c741ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7406426641094094"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qualité de l'ajustement \n",
    "hypothesis.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8e54ed",
   "metadata": {},
   "source": [
    "`score()` renvoie le coefficient de détermination R au carré pour la prédiction. Il s'agit d'une mesure entre 0/1 qui compare le prédicteur à une moyenne simple. Les valeurs hautes indiquent que le prédicteur fonctionne correctement. \n",
    "\n",
    "### Classe de transformation :\n",
    "Applique des transformations à d'autres tableaux de données en s'appuyant sur la phase d'ajustement. Il n'y a pas de méthode `transform` pour la régression linéaire, mais la plupart des autres algorithmes de prétraitement en disposent. \n",
    "`MinMaxScaler()` est ainsi capable de transformer les valeurs dans une plage spécifiée par une valeur minimale et une maximale, en apprenant la formule de transformation à partir d'un tableau d'exemple : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6efe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01116872 0.         0.01979472 0.         0.23662551 0.65893849\n",
      "  0.57775489 0.44288845 0.08695652 0.02480916 0.78723404 0.88173887\n",
      "  0.06263797]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X)\n",
    "# on applique les valeurs min/max apprises sur X\n",
    "print(scaler.transform(new_observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6cc36",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "\n",
    "## La technique de hachage\n",
    "Les fonctions de hachage servent à transformer n'importent quelles données d'entrée en données de sortie ayant des caractéristiques prévisibles. En général, la valeur renvoyée est liée à un intervalle particulier, dont les bornes vont par exemple d'une valeur négative à une valeur positive, ou seulement d'une valeur positive à une autre. Cela revient un peu à **appliquer un standard à vos données** : quelles que soient les valeurs fournies, le produit sera toujours le même.\n",
    "\n",
    "= fourni une valeur numérique pour une valeur d'entrée, ex : le mot 'chien' renverra toujours la même valeur numérique.\n",
    "= transforme en nombre.\n",
    "= on ne peut pas revenir à la valeur de départ à partir de celle d'arrivée. \n",
    "\n",
    "### Exemple avec Python et la fonction `hash()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0b8e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7212491160745632632"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash('Exemple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e286c",
   "metadata": {},
   "source": [
    "## Codage un sur N ou one-hot :\n",
    "\n",
    "Chaîne = 'Python for data science'\n",
    "\n",
    "1- **Affectation d'un nombre arbitraire à chaque mot**, par exemple Python=0, for=1, data et science 2 et 3.\n",
    "2- **Initialisation du vecteur en comptant le nombre de mots uniques qui ont été associés à un code dans la 1ère étape.**\n",
    "3- **Utilisation des codes de l'étape 1 comme index pour insérer des valeurs dans le vecteur, en assignant la valeur 1 dès qu'il y a coïncidence avec un mot de la phrase. \n",
    "\n",
    "= valeur numérique de 1 soit [1, 1, 1, 1]\n",
    "\n",
    "S'il faut convertir la phrase \"Python for machine learning\", 2 nouveaux mots sont à traiter.\n",
    "\n",
    "1- **Affectation des nouveaux codes :** machine=4 et learning=5, **ce qui correspond à l'opération de codage**.\n",
    "2- **Agrandissement du vecteur précédent pour accueillir les nouveaux mots :** [1, 1, 1, 1, 0, 0] \n",
    "3- **Calcul du vecteur pour la nouvelle chaîne :** [1, 1, 0, 0, 1, 1]\n",
    "\n",
    "Ce codage est assez efficace car il produit des vecteurs de caractéristiques bien ordonnés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de4a7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'python': 4, 'for': 1, 'data': 0, 'science': 5, 'machine': 3, 'learning': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "oh_encoder = CountVectorizer()\n",
    "oh_encoded = oh_encoder.fit_transform(['Python for data science', 'Python for machine learning'])\n",
    "\n",
    "print(oh_encoder.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1087183f",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "<br>\n",
    "\n",
    "## Matrices creuses et sélection déterministe\n",
    "\n",
    "Quand la plupart des valeurs de la matrices sont proches de 0, il est intéressant d'utiliser une matrice creuse. \n",
    "Une matrice creuse (sparse matrix) stocke pour toutes les cellules de la matrice les coordonnées des cellules et de leurs valeurs et non toute l'information. Lorsque l'application demande des données pour une cellule vide, la matrice renvoie la valeur zéro, après avoir cherché les coordonnées et n'avoir rien trouvé. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Calculer le temps d'exécution\n",
    "\n",
    "- `%timeit`: calcule le meilleur temps d'exécugtion d'une instruction (d'une ligne)\n",
    "- `%%timeit`: calcule le meilleur temps d'exécution de la séquence d'instructions d'une cellule.\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## Statistiques descriptives pour données numériques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8c9934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement du dataframe iris\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['group'] = pd.Series([iris.target_names[k] for k in iris.target], dtype='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09052cd7",
   "metadata": {},
   "source": [
    "### Indicateurs de tendance centrale :\n",
    "- Moyenne \n",
    "- Médiane\n",
    "\n",
    "= permettent d'avoir une 1ère idée de la **centralisation des données et de leur symétrie**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bf44bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    5.843333\n",
       "sepal width (cm)     3.057333\n",
       "petal length (cm)    3.758000\n",
       "petal width (cm)     1.199333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moyenne\n",
    "iris_df.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8421bb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    5.80\n",
       "sepal width (cm)     3.00\n",
       "petal length (cm)    4.35\n",
       "petal width (cm)     1.30\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Médiane\n",
    "iris_df.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4740eb62",
   "metadata": {},
   "source": [
    "Cette valeur médiane permet de localiser la position de la séparation entre les 2 moitiés de valeurs. La médiane est moins influencée par les cas anormaux ou par une distribution déséquilibrée des valeurs autour de la moyenne. \n",
    "\n",
    "## Variance, écart type et étendue\n",
    "\n",
    "Il s'agit ensuite de mesurer la **variance** ou plutôt sa racine carrée qui correspond à l'**écart type** (standard deviation). L'**écart type** donne autant d'informations que la variance, mais il est plus facile à comparer à la moyenne parce que l'unité de mesure est la même. La **variance** constitue un bon indicateur de l'intérêt d'une moyenne pour connaître la distribution des variables ; en effet, elle informe sur la façon dont les valeurs de la variable sont distribuées autour de la moyenne. Plus la **variance est élevée, plus loin peuvent se trouver certaines valeurs par rapport à la moyenne**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "db3c46b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0.828066\n",
       "sepal width (cm)     0.435866\n",
       "petal length (cm)    1.765298\n",
       "petal width (cm)     0.762238\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## écart type\n",
    "iris_df.std(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef3a057",
   "metadata": {},
   "source": [
    "On peut ensuite mesurer l'**étendue** (**range**) qui est la différence entre la valeur min/max pour chaque variable quantitative. Elle permet d'en apprendre plus au sujet des différences d'échelle entre les variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ed21092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    3.6\n",
      "sepal width (cm)     2.4\n",
      "petal length (cm)    5.9\n",
      "petal width (cm)     2.4\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(iris_df.max(numeric_only=True) - iris_df.min(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013520f",
   "metadata": {},
   "source": [
    "## Utilisation des centiles\n",
    "\n",
    "La médiane permet de connaître la position centrale de la distribution de valeurs, mais d'autres positions peuvent être intéressantes :\n",
    "- quartile inférieur (25%)\n",
    "- quartile supérieur (75%)\n",
    "\n",
    "= aident à déterminer la distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b70cd63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0.00                4.3               2.0               1.00               0.1\n",
      "0.25                5.1               2.8               1.60               0.3\n",
      "0.50                5.8               3.0               4.35               1.3\n",
      "0.75                6.4               3.3               5.10               1.8\n",
      "1.00                7.9               4.4               6.90               2.5\n"
     ]
    }
   ],
   "source": [
    "print(iris_df.quantile([0,.25,.50,.75,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f68b54c",
   "metadata": {},
   "source": [
    "La différence entre les quartiles sup/inf correspond à l'**écart interquartile** (IQR). Cette mesure permet d'estimer l'échelle des variables les plus intéressantes. Cet écart aide à connaître les limites plausibles de la distribution. Les valeurs situées sous le quartier inférieur et jusqu'au minimum, et celles situées au-dessus du quartier supérieur sont très rares, mais peuvent impacter négativement les résultats : ce sont das cas aberrants.\n",
    "\n",
    "## Définitions des paramètres de forme (normalité)\n",
    "\n",
    "- coefficient d'**asymétrie** (skewness) : elle est exprimée par rapport à la moyenne. Si elle est négative, la branche gauche est trop longue et l'essentiel des observations se situe du côté droit de distribution. Si elle est positive, c'est le contraire.\n",
    "\n",
    "- **Kurtosis** (ou **acuité**) : elle permet de voir si les pics et creux de la distribution ont la forme approprée. Si la valeur est supérieure à zéro, la distribution est trop plate.\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## Covariance et corrélation\n",
    "\n",
    "La **covariance** permet de savoir si les 2 variables se comportent de la même façon par rapport à leur moyenne. L'association est dite positive lorsque les valeurs isolées des 2 variables sont la plupart au-dessus ou la plupart en dessous de la moyenne correspondante. Les 2 tendent donc à converger et vous pouvez prédire le comportement de l'une par rapport à l'autre. La covariance est dans ce cas une valeur positive et plus elle est importante, plus elle est forte.\n",
    "\n",
    "En revanche, si une variable est en général au-dessus et l'autre en général au-dessous de la moyenne correspondante, l'association est négative. Même si cela signe une divergence, la situation permet de faire des prédictions. En observant l'état de l'une, vous pouvez deviner l'état probable de l'autre, bien qu'elles soient en sens opposé. La covariance est dans ce cas une valeur négative.\n",
    "\n",
    "La 3ème possibilité correspond au cas où les 2 variables divergent ou convergent de temps à autres. La covariance va tendre vers 0, ce qui prouve que les variables ne partagent que peu de causes et ont donc des comportements indépendants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9352e120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>0.685694</td>\n",
       "      <td>-0.042434</td>\n",
       "      <td>1.274315</td>\n",
       "      <td>0.516271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <td>-0.042434</td>\n",
       "      <td>0.189979</td>\n",
       "      <td>-0.329656</td>\n",
       "      <td>-0.121639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>1.274315</td>\n",
       "      <td>-0.329656</td>\n",
       "      <td>3.116278</td>\n",
       "      <td>1.295609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>0.516271</td>\n",
       "      <td>-0.121639</td>\n",
       "      <td>1.295609</td>\n",
       "      <td>0.581006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "sepal length (cm)           0.685694         -0.042434           1.274315   \n",
       "sepal width (cm)           -0.042434          0.189979          -0.329656   \n",
       "petal length (cm)           1.274315         -0.329656           3.116278   \n",
       "petal width (cm)            0.516271         -0.121639           1.295609   \n",
       "\n",
       "                   petal width (cm)  \n",
       "sepal length (cm)          0.516271  \n",
       "sepal width (cm)          -0.121639  \n",
       "petal length (cm)          1.295609  \n",
       "petal width (cm)           0.581006  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcul d'une matrice de covariance (avec pandas)\n",
    "iris_df.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebda55",
   "metadata": {},
   "source": [
    "La **corrélation** est une estimation de la **covariance** après standardisation des variables. Les valeurs de corrélation sont bornées entre -1 et +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e7007527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.117570</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <td>-0.117570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.428440</td>\n",
       "      <td>-0.366126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>0.871754</td>\n",
       "      <td>-0.428440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>0.817941</td>\n",
       "      <td>-0.366126</td>\n",
       "      <td>0.962865</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "sepal length (cm)           1.000000         -0.117570           0.871754   \n",
       "sepal width (cm)           -0.117570          1.000000          -0.428440   \n",
       "petal length (cm)           0.871754         -0.428440           1.000000   \n",
       "petal width (cm)            0.817941         -0.366126           0.962865   \n",
       "\n",
       "                   petal width (cm)  \n",
       "sepal length (cm)          0.817941  \n",
       "sepal width (cm)          -0.366126  \n",
       "petal length (cm)          0.962865  \n",
       "petal width (cm)           1.000000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exemple avec pandas\n",
    "iris_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1cb9fd",
   "metadata": {},
   "source": [
    "Une autre technique intéressante consiste à élever la corrélation au carré. Cela fait perdre le signe de la relation et la nouvelle valeur permet de connaître le pourcentage d'informations partagées entre 2 variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4004f0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013823</td>\n",
       "      <td>0.759955</td>\n",
       "      <td>0.669028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <td>0.013823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.183561</td>\n",
       "      <td>0.134048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>0.759955</td>\n",
       "      <td>0.183561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.927110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>0.669028</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>0.927110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "sepal length (cm)           1.000000          0.013823           0.759955   \n",
       "sepal width (cm)            0.013823          1.000000           0.183561   \n",
       "petal length (cm)           0.759955          0.183561           1.000000   \n",
       "petal width (cm)            0.669028          0.134048           0.927110   \n",
       "\n",
       "                   petal width (cm)  \n",
       "sepal length (cm)          0.669028  \n",
       "sepal width (cm)           0.134048  \n",
       "petal length (cm)          0.927110  \n",
       "petal width (cm)           1.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.corr()**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae356d6",
   "metadata": {},
   "source": [
    "---\n",
    "<br>\n",
    "# Réduction de dimensionnalité \n",
    " \n",
    " La grande quantité de dimensions des datas oblige à chercher des techniques pour filtrer les informations, en ne conservant que celles qui peuvent le mieux aider à résoudre le problème. Ce genre de filtre va réduire les dimensions en supprimant d'abord toutes les informations redondantes.\n",
    " \n",
    " ## Décomposition en valeurs singulières (Single Value Decomposition ou SVD)\n",
    " La SVD reçoit en entrée une matrice pour en produire 3 en sorties. Ces dernières permettent de reconstruire la maîtrise d'entrée en les multipliant entre elles. \n",
    " \n",
    "` M = U * s * Vh`\n",
    "\n",
    "- **U**: contient toutes les informations à propos des lignes ou observations ;\n",
    "- **Vh**: contient toutes les informations concernant les colonnes ou caractéristiques ;\n",
    "- **s**: contient la description du processus SVD (une sorte de journal)\n",
    "\n",
    "En construisant les nouvelles matrices, nous séparons les informations concernant les lignes de celles concernant les colonnes (qui étaient liées dans la première matrice). Toutes les informations utiles sont ramenées dans les premières colonnes des nouvelles matrices. \n",
    "\n",
    "La matrice résultante **s** permet de savoir comment la compression a été réalisé. La somme de toutes les valeurs dans **s** indique combien d'informations étaient présentes dans la matrice de départ. De plus, chaque valeur dans **s** indique la quantité de donnée qui a été accumulée dans chacune des colonnes respectives de **U** et de **Vh**.\n",
    "\n",
    "## Pratique de la réduction de dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "297f94db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4]\n",
      " [2 3 5]\n",
      " [1 2 3]\n",
      " [5 4 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# création d'une matrice\n",
    "A = np.array([[1, 3, 4], [2, 3, 5], [1, 2, 3], [5, 4, 6]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b88d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3) (3,) (3, 3)\n",
      "[12.26362747  2.11085464  0.38436189]\n"
     ]
    }
   ],
   "source": [
    "# création des 3 matrices\n",
    "U, s, Vh = np.linalg.svd(A, full_matrices=False)\n",
    "print(np.shape(U), np.shape(s), np.shape(Vh))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea0abc",
   "metadata": {},
   "source": [
    "La première colonne contient le plus d'informations (environ 83%). La deuxième colonne en contient 14% et la troisième le reste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "378bd5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 3. 4.]\n",
      " [2. 3. 5.]\n",
      " [1. 2. 3.]\n",
      " [5. 4. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# reconstruction de la matrice de départ\n",
    "print(np.dot(np.dot(U, np.diag(s)), Vh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b477093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  2.8 4.1]\n",
      " [2.  3.2 4.8]\n",
      " [1.  2.  3. ]\n",
      " [5.  3.9 6. ]]\n"
     ]
    }
   ],
   "source": [
    "# réduction de données : exclure la 3ème colonne (celle qui a le moins de poids)\n",
    "print(np.round(np.dot(np.dot(U[:,:2], np.diag(s[:2])),\n",
    "                     Vh[:2, :]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "756a5e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1 2.5 3.7]\n",
      " [2.6 3.1 4.6]\n",
      " [1.6 1.8 2.8]\n",
      " [3.7 4.3 6.5]]\n"
     ]
    }
   ],
   "source": [
    "# suppression de la deuxième colonne \n",
    "print(np.round(np.dot(np.dot(U[:,:1], np.diag(s[:1])),\n",
    "                     Vh[:1, :]), 1))\n",
    "\n",
    "# perte de données, compensée sur des centaines de colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc72f5f",
   "metadata": {},
   "source": [
    "## Analyse de facteurs et PCA\n",
    "\n",
    "En étudiant toutes les corrélations possibles d'une variable avec les autres du même groupe, vous finissez par aboutir à 2 types de variance :\n",
    "\n",
    "- **Variance unique** : certaines variances restent uniques à la variable examinée, qui ne peut pas être associée à l'évolution d'aucune autre variable.\n",
    "\n",
    "- **Variance partagée ou commune**: la variance est partagée au moins en partie avec celle d'autres variables, ce qui confirme une redondance dans les données. Cette redondance signifie que vous pourrez préserver la même information en partant de valeurs légèrement différentes dans d'autres caractéristiques et pour de nombreuses autres observations. \n",
    "\n",
    "Il s'agit ensuite de chercher les causes de cette variance partagée. Il existe deux techniques d'analyse :\n",
    "- **l'analyse de facteurs**\n",
    "- **l'analyse par composantes principales (PCA : Principal Components Analysis)**\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
