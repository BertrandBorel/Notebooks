{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Data Augmentation avec Keras </center>\n",
        "\n",
        "**Source :** Cours de Franck Bardol, [LinkedIn Learning](https://www.linkedin.com/learning/decouvrir-le-deep-learning-avec-keras/2228070?autoSkip=true&autoplay=true&resume=false)."
      ],
      "metadata": {
        "id": "cP5EeTsAmSlg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNfVD-LEmhWe",
        "outputId": "cb04cb5d-8965-4e27-fe2e-dd1ac17c741b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!/usr/bin/env python2\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@author: franck BARDOL\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n@author: franck BARDOL\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mzjd3JTlKMh"
      },
      "source": [
        "# Data Augmentation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhKSplA0lqJ_"
      },
      "source": [
        "## Objectif\n",
        "Nous allons voir ensemble :\n",
        "* Comment améliorer la performance des réseaux de convolution ? \n",
        "* Comment utiliser les réseaux à convolution sur de petits jeux de données ?\n",
        "\n",
        "Pour réaliser cela, nous allons utiliser une technique dite de *data augmentation*.\n",
        "\n",
        "## Motivations\n",
        "Les Réseaux à convolution nécessitent d'importants volumes de données pour être entrainés de manière satisfaisante.\n",
        "\n",
        "Souvent, les praticiens ne disposent *pas* du **volume de données** nécessaire.\n",
        "\n",
        "Dans ce cas, les alternatives sont les suivantes :\n",
        "* ne pas faire du Deep Learning sur un réseau conséquent -> concevoir et entrainer un petit réseau\n",
        "* concevoir un algorithme de Machine Learning \"traditionnel\" (Random Forest, SVM, ...)\n",
        "* **augmenter** son data-set\n",
        "\n",
        "## Que signifie \"augmenter\" son data-set ?\n",
        "Augmenter son data-set signifie construire de nouveaux exemples à partir des données dont on dispose.\n",
        "\n",
        "Pour cela, on transforme les données, on les manipule en quelque sorte afin de les faire paraître différentes, nouvelles, originales. \n",
        "\n",
        "\n",
        "De cette façon, le modèle de Deep Learning apprendra des éléments significatifs grâce aux données augmentées.\n",
        "\n",
        "Il va **généraliser correctement**\n",
        "\n",
        "## Augmentation ... quelles opérations ?\n",
        "On change de manière aléatoire : \n",
        "* position\n",
        "* orientation des images\n",
        "\n",
        "## Keras \n",
        "L'API de Keras crée à la volée un flot de données augmentées.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUxHBNiFrxHm"
      },
      "source": [
        "#==========\n",
        "# IMPORT DONNEES\n",
        "#==========\n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "# \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import  matplotlib.pyplot as pl\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 4 axis : samples ,  width , height , channel \n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28 , 1)\n",
        "train_images = train_images.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qDh8hE6Iusc"
      },
      "source": [
        "## Augmentation : implémentation avec Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVQ6068UkgEA"
      },
      "source": [
        "\n",
        "\n",
        "# data preparation\n",
        "datagenerator = ImageDataGenerator(\n",
        "                                   # definir data preparation / augmentation : rotation\n",
        "                                   rotation_range = 90,\n",
        "                                   zoom_range=0.2, \n",
        "                                   # zoom random\n",
        "                                   horizontal_flip = False,\n",
        "                                   # flip random\n",
        "                                   vertical_flip = False,\n",
        "                                   width_shift_range = 0.1,\n",
        "                                   # shift random horizontal \n",
        "                                   height_shift_range = 0.1)\n",
        " \n",
        "# entrainement sur les donnees \n",
        "datagenerator.fit(train_images)\n",
        "# configure batch. run : UN batch \n",
        "bcl = 0\n",
        "\n",
        "# creation du flow (un batch) after performing data augmentation:\n",
        "for batch_x, batch_y in datagenerator.flow(train_images, train_labels, batch_size = 1):\n",
        "    pl.figure()\n",
        "    pl.imshow(batch_x[0].reshape(28, 28), \n",
        "              cmap = pl.get_cmap('gray'))\n",
        "    bcl = bcl +1\n",
        "    pl.show()\n",
        "    if bcl > 3:\n",
        "      # interruption du batch \n",
        "      break\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}