{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYIvjsTmUPAb"
      },
      "source": [
        "# Reconnaissance Optique de Caractères avec Keras\n",
        "\n",
        "**Source :** Cours de Franck Bardol, [LinkedIn Learning](https://www.linkedin.com/learning/decouvrir-le-deep-learning-avec-keras/bienvenue-dans-le-deep-learning-avec-keras?autoplay=true).\n",
        "\n",
        "## OCR : Optical Caracter Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pdgxpKGmYaN"
      },
      "source": [
        "#!/usr/bin/env python2\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@author: franck BARDOL\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnWxcD_PUdan"
      },
      "source": [
        "## Objectif : \n",
        "Nous allons voir comment apprendre à reconnaître des caractères optiques avec Keras.\n",
        "\n",
        "Il s'agit de reconnître des chiffres traçés à la main.\n",
        "\n",
        "Ce type d'application est déployé pour la lecture optique des chèques bancaires par exemple.\n",
        "\n",
        "Nous allons écrire un **Réseau de neurones à Convolution** afin de reconnaître les caractères manuscrits. \n",
        "\n",
        "\n",
        "Le réseau de neurones devra apprendre à lire les chiffres. C'est-à-dire, prédire correctement la valeur du chiffre tracé.\n",
        "\n",
        "\n",
        "Cela n'a rien d'évident. \n",
        "Là où un humain voit une image représentant un chiffre, le réseau ne voit, pour sa part, qu'un ensemble de pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqXINn11WD_u"
      },
      "source": [
        "## Importation des librairies nécessaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIhR1rOxQmAy"
      },
      "source": [
        "# ==========================================\n",
        "#                   MNIST data set\n",
        "# ==========================================\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mohzkg3tWLXJ"
      },
      "source": [
        "## Le data-set \n",
        "On importe les images du [MNIST](https://en.wikipedia.org/wiki/MNIST_database).\n",
        "C'est un ensemble de 60,000 images de chiffres en N&B "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV72Nst2V4tz"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print(\"nb images = \",train_images.shape[0])\n",
        "print(\"unique label = \",np.unique(train_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSO-edguVhvP"
      },
      "source": [
        "### Préparation des données\n",
        "On doit \"re-tailler\" les images dans un format standard.\n",
        "\n",
        "Le format attendu est une image de taille 28 pixel sur 28 pixel.\n",
        "\n",
        "Les images sont Noir & Blanc. On ajoute une dimension supplémentaire pour tenir compte de cette information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdgwe6ijYahH"
      },
      "source": [
        "print(\"dimension data set :\" , train_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-d7H8OvefHd"
      },
      "source": [
        "### Visualisation de quelques images\n",
        "Avant de se lancer dans l'écriture d'un modèle de Deep Learning, il est toujours intéressant de **visualiser** les données.\n",
        "\n",
        "Pour cela, on utilise la librairie *matplotlib*\n",
        "\n",
        "Lien internet [matplotlib](https://matplotlib.org/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii8jlVLbe0vb"
      },
      "source": [
        "# choix du numéro de l'image \n",
        "num_img = 100\n",
        "pl.figure()\n",
        "pl.imshow(train_images[num_img,:,:], cmap = pl.get_cmap('gray'))\n",
        "pl.show()\n",
        "\n",
        "# quel chiffre ?\n",
        "print(train_labels[num_img])\n",
        "num_label = train_labels[num_img]\n",
        "print(\"c est un : \" , num_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdiER61nZPUK"
      },
      "source": [
        "### Redimension - Normalisation des images\n",
        "* On re-dimensionne (*reshape*) pour ajouter **une** dimension.\n",
        "Si les images étaient en couleur, on devrait alors ajouter **trois** dimensions (RGB : red - green - blue).\n",
        "* On normalise les images d'origine qui sont encodées sur 255 niveaux de gris. \n",
        "Les valeurs des pixels seront donc comprises entre 0 et 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiA-udMiVjH4"
      },
      "source": [
        "# re-dimension :\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "# normalisation :\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MpHlQngbH08"
      },
      "source": [
        "### One hot encoding des labels \n",
        "Les outputs (labels) sont une étiquette (comprise entre 0 et 9) qui représente la valeur du chiffre traçé.\n",
        "C'est la sortie que le réseau devra apprendre à reconnaitre.\n",
        "\n",
        "Le *One Hot encoding* est un traitement classique. \n",
        "\n",
        "Il consiste à étendre la **dimension** de la sortie.\n",
        "On passe d'un nombre entre 0 et 9 à un vecteur (tableau) de dimension 9.\n",
        "\n",
        "\n",
        "Exemple de One Hot Encoding sur des nombres compris entre 0 et 2 : \n",
        "\n",
        "0 -> {1 , 0 , 0} \n",
        "\n",
        "1 -> {0 , 1 , 0} \n",
        "\n",
        "2 -> {0 , 0 , 1} \n",
        "\n",
        "Ce traitement facilite l'apprentissage du réseau\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nl8wY_-bZpL"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL_9v-YWVnTy"
      },
      "source": [
        "# One Hot Encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49TL_V2QfVre"
      },
      "source": [
        "## Deep Learning : Convolutionnal Neural Network avec Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2lrGMtNVBhB"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(16, (3, 3), activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehf-TFPpgIQX"
      },
      "source": [
        "### Couche  de traitement *flatten* \n",
        "Aprés les couches de **convolution**, on doit **toujours** ajouter une couche de traitement **Flatten**.\n",
        "\n",
        "Cette couche met à plat les structures en 2D issues de la convolution.\n",
        "\n",
        "La couche *Flatten*  assure le passage 2D -> 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BADmF60gEQ5"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIG8h2beVWBv"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnlfoRcBVGIN"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaPOvHAGd_L9"
      },
      "source": [
        "### remarque :\n",
        "l'apprentissage du modèle est lent. \n",
        "Vous pouvez l'accélérer en déportant les calculs sur GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUyVEDvRVJPM"
      },
      "source": [
        "history = model.fit(train_images, \n",
        "          train_labels, \n",
        "          validation_split = 0.1,\n",
        "          epochs = 10, \n",
        "          batch_size = 500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bL9Sri4VPAb"
      },
      "source": [
        "pl.figure()\n",
        "pl.plot(history.history['loss'])\n",
        "pl.plot(history.history['val_loss'])\n",
        "pl.legend([\"training\",\"test\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcI_c6plfpOa"
      },
      "source": [
        "### Exercice\n",
        "Observez la courbe d'apprentissage.\n",
        "\n",
        "L'apprentissage s'est-il déroulé correctement selon vous ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91pTDnIjeTG4"
      },
      "source": [
        "## Performance du modèle \n",
        "Accuracy : % d'instances bien classées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tfyFqOFVLca"
      },
      "source": [
        "# Evaluation\n",
        "print(model.evaluate(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK_xESlje5EI"
      },
      "source": [
        "np.argmax(test_labels , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5s06eT6gfgw"
      },
      "source": [
        "## Matrice de Confusion \n",
        "\n",
        "Partie avancée. Cette partie peut être passée en 1ère lecture ...\n",
        "\n",
        "Nous utilisons une matrice de confusion pour interpréter les résultats.\n",
        "\n",
        "La matrice de confusion est un matrice *carrée* comportant autant de lignes qu'il y a de classes dans le problème.\n",
        "\n",
        "Ici, nous avons **dix** classes correspondant aux chiffres de 0 à 9. Il y aura donc **dix** lignes et **dix** colonnes. \n",
        "Dans notre cas, c'est une matrice 10 x 10\n",
        "\n",
        "En colonne, on reporte les valeurs **prédites** par l'algorithme. \n",
        "(\"*predicted*\" dans le tableau ci-dessous).\n",
        "\n",
        "En ligne, on reporte les valeurs **observées** dans la réalité.\n",
        "(\"*True*\" dans le tableau ci-dessous).\n",
        "\n",
        "On reporte dans le tableau les instances de la manière suivante :\n",
        "\n",
        "> - dans la diagonale principale du tableau le nombre d'instances correctement prédites.  \n",
        "Les vrais-négatifs (*true negative* : `TN`) et les vrais-positifs (*true positive* : `TP`).\n",
        "> - dans les cellules restantes, on reporte les erreurs de classification : les faux-positifs (`FP`) et les faux-négatifs (`FN`) \n",
        "\n",
        "Pour aller plus loin sur la matrice de confusion :\n",
        "https://fr.wikipedia.org/wiki/Matrice_de_confusion\n",
        "\n",
        "Affichage d'une matrice de confusion :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVfnCAHRdwnA"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "y_pred = model.predict(test_images)\n",
        "# pick the best predicted (max)\n",
        "y_pred = np.argmax(y_pred , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72S6eMlE9-kT"
      },
      "source": [
        "### Affichage non formaté de la matrice "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-oxToAng6vB"
      },
      "source": [
        "# les labels (etiquettes)\n",
        "lbls = np.argmax(test_labels , axis = 1)\n",
        "conf_mat = confusion_matrix(lbls  , y_pred ,labels = [0,1,2,3,4,5,6,7,8,9])\n",
        "print(conf_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMEw05Qd-LhN"
      },
      "source": [
        "### Affichage formaté de la matrice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kpmWUjkfgtZ"
      },
      "source": [
        "cm_display = ConfusionMatrixDisplay(conf_mat,[0,1,2,3,4,5,6,7,8,9])\n",
        "cm_display.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWwlH1PhzUu6"
      },
      "source": [
        "### Analyse de la plus grande erreur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWmZhJrZiMoQ"
      },
      "source": [
        "#  ignorer la diagonale de la matrice de confusion\n",
        "mask = np.ones(conf_mat.shape, dtype=bool)\n",
        "np.fill_diagonal(mask, 0)\n",
        "# pick max -> instances mal classfiées\n",
        "max_value = conf_mat[mask].max()\n",
        "\n",
        "position = np.where(conf_mat == max_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ZBlodr-XiC"
      },
      "source": [
        "print(\"plus grand nombre d'erreur : \" , max_value)\n",
        "print(\"position du plus grand nombre d'erreur : ligne {}, colonne {}\".format(position[0] , position[1]))\n",
        "print(\"on confond les {} (vrai label) avec les {} (label prédit)\".format(position[0] , position[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr8exaRT_EGz"
      },
      "source": [
        "### Affichage de toutes les plus grandes erreurs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKGqKHxr10jC"
      },
      "source": [
        "# intersection valeur prédite , vraie valeur -> position des plus grandes erreurs\n",
        "s_predict = set(np.where(y_pred == position[1])[0])\n",
        "s_true = set( np.where(lbls == position[0])[0])\n",
        "# on stocke les positions des erreurs \n",
        "idx_err = s_predict.intersection(s_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01U3lSDT4gu8"
      },
      "source": [
        "# retour au format d'origine pour affichage \n",
        "tst_img = test_images.reshape((10000, 28, 28))\n",
        "# afficher petites vignettes \n",
        "pl.rcParams[\"figure.figsize\"] = (1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAqruEJ3z5IL"
      },
      "source": [
        "for item in idx_err:\n",
        "  # choix du numéro de l'image \n",
        "  num_img = item\n",
        "  pl.figure()\n",
        "  pl.imshow(tst_img[num_img,:,:], cmap = pl.get_cmap())\n",
        "  pl.show()\n",
        "\n",
        "  # quel chiffre ?\n",
        "  num_label = test_labels[num_img]\n",
        "  print(\"vrai label : {}, prediction : {}\".format(np.argmax(num_label) , y_pred[item]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}