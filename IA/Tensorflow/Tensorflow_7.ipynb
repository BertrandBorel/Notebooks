{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Régler les hyperparamètres avec Keras Tuner </center>\n",
        "\n",
        "**Source :** https://www.tensorflow.org/tutorials/keras/keras_tuner?hl=fr\n",
        "\n",
        "Le Keras Tuner est une bibliothèque qui vous aide à choisir l'ensemble optimal d'hyperparamètres pour votre programme TensorFlow. Le processus de sélection du bon ensemble d'hyperparamètres pour votre application d'apprentissage automatique (ML) est appelé *réglage d'hyperparamètres* ou *hyperréglage*.\n",
        "\n",
        "Les hyperparamètres sont les variables qui régissent le processus de formation et la topologie d'un modèle ML. Ces variables restent constantes tout au long du processus de formation et ont un impact direct sur les performances de votre programme ML. Les hyperparamètres sont de deux types :\n",
        "- **Hyperparamètres de modèle** qui influencent la sélection du modèle, tels que le nombre et la largeur des couches masquées\n",
        "\n",
        "- **Hyperparamètres d'algorithme** qui influencent la vitesse et la qualité de l'algorithme d'apprentissage, tels que le taux d'apprentissage pour Stochastic Gradient Descent (SGD) et le nombre de voisins les plus proches pour un classificateur ak Nearest Neighbors (KNN)\n",
        "\n"
      ],
      "metadata": {
        "id": "yxeQAdkn94fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importations"
      ],
      "metadata": {
        "id": "5uU813v8-P2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# pip install -q -U keras-tuner\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "ib_1cnzk-sOl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jeu de données"
      ],
      "metadata": {
        "id": "U3FbyXY_-viP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghyrETlY_Hfs",
        "outputId": "cce685de-54f3-4ebb-907b-e193a1bab235"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values between 0 and 1\n",
        "img_train = img_train.astype('float32') / 255.0\n",
        "img_test = img_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "Cz3ke63a_Hxs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construction du modèle\n",
        "\n",
        "Lorsque vous créez un modèle pour l'hyperréglage, vous définissez également l'espace de recherche d'hyperparamètres en plus de l'architecture du modèle. Le modèle que vous configurez pour l'hyperréglage s'appelle un *hypermodèle* .\n",
        "\n",
        "Vous pouvez définir un hypermodèle selon deux approches :\n",
        "\n",
        "En utilisant une fonction de création de modèle\n",
        "En sous-classant la classe `HyperModel` de l'API Keras Tuner.\n",
        "\n",
        "Dans ce didacticiel, vous utilisez une fonction de générateur de modèles pour définir le modèle de classification d'images. La fonction de générateur de modèles renvoie un modèle compilé et utilise des hyperparamètres que vous définissez en ligne pour ajuster le modèle."
      ],
      "metadata": {
        "id": "ve9-VusW1Nmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ySdXUm4O_I4i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instanciez le tuner et effectuez un hypertuning"
      ],
      "metadata": {
        "id": "7-6U-aPiBvxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')"
      ],
      "metadata": {
        "id": "_7z_r06WDf1w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# création d'un rappel\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "IgprJPFbDgK1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rechercher les hyperparamètres\n",
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmVt6DUcJtny",
        "outputId": "052ffc0b-7afb-4482-b73d-65f2a149910c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 02m 23s]\n",
            "val_accuracy: 0.8847500085830688\n",
            "\n",
            "Best val_accuracy So Far: 0.8924999833106995\n",
            "Total elapsed time: 00h 24m 01s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 416 and the optimal learning rate for the optimizer\n",
            "is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entraînement du modèle"
      ],
      "metadata": {
        "id": "8_bRYr-cJy4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBndhbWCJ8mS",
        "outputId": "8d5451bb-bf5d-4fc1-ceb1-0a76c5c488e5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.4931 - accuracy: 0.8252 - val_loss: 0.4065 - val_accuracy: 0.8561\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3699 - accuracy: 0.8657 - val_loss: 0.3658 - val_accuracy: 0.8652\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3326 - accuracy: 0.8779 - val_loss: 0.3330 - val_accuracy: 0.8764\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.3087 - accuracy: 0.8860 - val_loss: 0.3292 - val_accuracy: 0.8804\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2879 - accuracy: 0.8922 - val_loss: 0.3487 - val_accuracy: 0.8750\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2734 - accuracy: 0.8988 - val_loss: 0.3321 - val_accuracy: 0.8779\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2564 - accuracy: 0.9031 - val_loss: 0.3038 - val_accuracy: 0.8911\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2482 - accuracy: 0.9081 - val_loss: 0.3241 - val_accuracy: 0.8813\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2362 - accuracy: 0.9118 - val_loss: 0.3159 - val_accuracy: 0.8871\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2259 - accuracy: 0.9154 - val_loss: 0.3161 - val_accuracy: 0.8869\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2154 - accuracy: 0.9192 - val_loss: 0.3158 - val_accuracy: 0.8870\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2077 - accuracy: 0.9207 - val_loss: 0.3127 - val_accuracy: 0.8923\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.2019 - accuracy: 0.9239 - val_loss: 0.3001 - val_accuracy: 0.8962\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1935 - accuracy: 0.9279 - val_loss: 0.3197 - val_accuracy: 0.8936\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1861 - accuracy: 0.9283 - val_loss: 0.3314 - val_accuracy: 0.8926\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1805 - accuracy: 0.9319 - val_loss: 0.3694 - val_accuracy: 0.8845\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1752 - accuracy: 0.9329 - val_loss: 0.3345 - val_accuracy: 0.8940\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1673 - accuracy: 0.9362 - val_loss: 0.3361 - val_accuracy: 0.8978\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1639 - accuracy: 0.9384 - val_loss: 0.3434 - val_accuracy: 0.8908\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1587 - accuracy: 0.9412 - val_loss: 0.3408 - val_accuracy: 0.8937\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1520 - accuracy: 0.9434 - val_loss: 0.3476 - val_accuracy: 0.8902\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1539 - accuracy: 0.9416 - val_loss: 0.3498 - val_accuracy: 0.8956\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1412 - accuracy: 0.9471 - val_loss: 0.3627 - val_accuracy: 0.8937\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1378 - accuracy: 0.9470 - val_loss: 0.3905 - val_accuracy: 0.8897\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1344 - accuracy: 0.9495 - val_loss: 0.3641 - val_accuracy: 0.8938\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1318 - accuracy: 0.9512 - val_loss: 0.3782 - val_accuracy: 0.8955\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1255 - accuracy: 0.9520 - val_loss: 0.3831 - val_accuracy: 0.8878\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1254 - accuracy: 0.9533 - val_loss: 0.3963 - val_accuracy: 0.8931\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1199 - accuracy: 0.9545 - val_loss: 0.3849 - val_accuracy: 0.8976\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1221 - accuracy: 0.9542 - val_loss: 0.4272 - val_accuracy: 0.8913\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.1109 - accuracy: 0.9581 - val_loss: 0.3927 - val_accuracy: 0.8977\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1141 - accuracy: 0.9563 - val_loss: 0.4236 - val_accuracy: 0.8928\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1086 - accuracy: 0.9590 - val_loss: 0.4666 - val_accuracy: 0.8863\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1083 - accuracy: 0.9591 - val_loss: 0.4587 - val_accuracy: 0.8917\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1023 - accuracy: 0.9618 - val_loss: 0.4883 - val_accuracy: 0.8840\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1012 - accuracy: 0.9625 - val_loss: 0.4442 - val_accuracy: 0.8923\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0995 - accuracy: 0.9617 - val_loss: 0.4464 - val_accuracy: 0.8932\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0919 - accuracy: 0.9653 - val_loss: 0.4639 - val_accuracy: 0.8938\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0969 - accuracy: 0.9634 - val_loss: 0.4258 - val_accuracy: 0.8955\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0884 - accuracy: 0.9673 - val_loss: 0.4581 - val_accuracy: 0.8969\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0883 - accuracy: 0.9668 - val_loss: 0.4891 - val_accuracy: 0.8880\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0908 - accuracy: 0.9655 - val_loss: 0.4707 - val_accuracy: 0.8967\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0873 - accuracy: 0.9667 - val_loss: 0.4832 - val_accuracy: 0.8926\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0814 - accuracy: 0.9694 - val_loss: 0.4698 - val_accuracy: 0.8946\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0849 - accuracy: 0.9679 - val_loss: 0.4876 - val_accuracy: 0.8932\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0824 - accuracy: 0.9689 - val_loss: 0.4785 - val_accuracy: 0.8946\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0802 - accuracy: 0.9695 - val_loss: 0.5025 - val_accuracy: 0.8915\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0801 - accuracy: 0.9700 - val_loss: 0.5137 - val_accuracy: 0.8929\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0764 - accuracy: 0.9717 - val_loss: 0.5065 - val_accuracy: 0.8930\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0737 - accuracy: 0.9718 - val_loss: 0.5074 - val_accuracy: 0.8972\n",
            "Best epoch: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Réentraînement avec le nombre optimale d'epochs"
      ],
      "metadata": {
        "id": "EGxIRecJKCE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q4B2cQiR-5S",
        "outputId": "1c67c125-b34d-4b6b-9bea-af714ac34f87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.4941 - accuracy: 0.8229 - val_loss: 0.3937 - val_accuracy: 0.8563\n",
            "Epoch 2/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3685 - accuracy: 0.8665 - val_loss: 0.4190 - val_accuracy: 0.8432\n",
            "Epoch 3/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3299 - accuracy: 0.8790 - val_loss: 0.3552 - val_accuracy: 0.8703\n",
            "Epoch 4/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3047 - accuracy: 0.8879 - val_loss: 0.3322 - val_accuracy: 0.8795\n",
            "Epoch 5/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2832 - accuracy: 0.8941 - val_loss: 0.3582 - val_accuracy: 0.8788\n",
            "Epoch 6/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2705 - accuracy: 0.8999 - val_loss: 0.3210 - val_accuracy: 0.8870\n",
            "Epoch 7/18\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2577 - accuracy: 0.9038 - val_loss: 0.3246 - val_accuracy: 0.8863\n",
            "Epoch 8/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2438 - accuracy: 0.9093 - val_loss: 0.3133 - val_accuracy: 0.8882\n",
            "Epoch 9/18\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.2338 - accuracy: 0.9120 - val_loss: 0.3093 - val_accuracy: 0.8918\n",
            "Epoch 10/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2243 - accuracy: 0.9165 - val_loss: 0.3367 - val_accuracy: 0.8853\n",
            "Epoch 11/18\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2159 - accuracy: 0.9192 - val_loss: 0.3306 - val_accuracy: 0.8857\n",
            "Epoch 12/18\n",
            "1500/1500 [==============================] - 14s 9ms/step - loss: 0.2067 - accuracy: 0.9234 - val_loss: 0.3243 - val_accuracy: 0.8898\n",
            "Epoch 13/18\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1984 - accuracy: 0.9255 - val_loss: 0.3446 - val_accuracy: 0.8827\n",
            "Epoch 14/18\n",
            "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1930 - accuracy: 0.9278 - val_loss: 0.3292 - val_accuracy: 0.8888\n",
            "Epoch 15/18\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1862 - accuracy: 0.9299 - val_loss: 0.3308 - val_accuracy: 0.8903\n",
            "Epoch 16/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1768 - accuracy: 0.9333 - val_loss: 0.3245 - val_accuracy: 0.8951\n",
            "Epoch 17/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1731 - accuracy: 0.9344 - val_loss: 0.3346 - val_accuracy: 0.8949\n",
            "Epoch 18/18\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1654 - accuracy: 0.9378 - val_loss: 0.3524 - val_accuracy: 0.8906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2a327a5c70>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation : "
      ],
      "metadata": {
        "id": "qrcTLIPdR_Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZH35-nmTygm",
        "outputId": "8ec2478a-ea5a-4364-f905-72ffea91373e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step - loss: 0.3866 - accuracy: 0.8831\n",
            "[test loss, test accuracy]: [0.3865816593170166, 0.8830999732017517]\n"
          ]
        }
      ]
    }
  ]
}