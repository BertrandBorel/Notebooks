{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25890cb7",
   "metadata": {},
   "source": [
    "# <center> Description des *Metrics* en Machine Learning </center>\n",
    "\n",
    "**source :** Boutaba, R., Salahuddin, M. A., Limam, N., Ayoubi, S., Shahriar, N., Estrada-Solano, F., & Caicedo, O. M. (2018). A comprehensive survey on machine learning for networking: evolution, applications and research opportunities. *Journal of Internet Services and Applications*, 9(1), 1-99.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527eb2f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Mean Absolute Error (MAE)** : Average of the absolute error between the actual and predicted values.\n",
    "Facilitates error interpretability.\n",
    "\n",
    "**Mean Squared Error (MSE)** : Average of the squares of the error between the actual and predicted\n",
    "values. Heavily penalizes large errors.\n",
    "\n",
    "**Mean Absolute Prediction Error (MAPE)** : Percentage of the error between the actual and predicted values. Not reliable for zero values or low-scale data.\n",
    "\n",
    "**Root MSE (RMSE)** : Squared root of MSE. Represents the standard deviation of the error between the actual and predicted values.\n",
    "\n",
    "**Normalized RMSE (NRMSE)** : Normalized RMSE. Facilitates comparing different models independently\n",
    "of their working scale.\n",
    "\n",
    "**Cross-entropy** : Metric based on the logistic function that measures the error between the actual and predicted values.\n",
    "\n",
    "**Accuracy** : Proportion of correct predictions among the total number of predictions. Not reliable for skewed class-wise data.\n",
    "\n",
    "**True Positive Rate (TPR) or recall** : Proportion of actual positives that are correctly predicted. Represents\n",
    "the sensitivity or detection rate (DR) of a model.\n",
    "\n",
    "**False Positive Rate (FPR)** : Proportion of actual negatives predicted as positives. Represents the\n",
    "significance level of a model.\n",
    "\n",
    "**True Negative Rate (TNR)** : Proportion of actual negatives that are correctly predicted. Represents\n",
    "the specificity of a model.\n",
    "\n",
    "**False Negative Rate (FNR)** : Proportion of actual positives predicted as negatives. Inversely proportional\n",
    "to the statistical power of a model.\n",
    "\n",
    "**Received Operating Characteristic (ROC)** : Curve that plots TPR versus FPR at different parameter settings. Facilitates analyzing the cost-benefit of possibly optimal models.\n",
    "\n",
    "**Area Under the ROC Curve (AUC)** : Probability of confidence in a model to accurately predict positive outcomes for actual positive instances.\n",
    "\n",
    "**Precision** : Proportion of positive predictions that are correctly predicted.\n",
    "\n",
    "**F-measure** : Harmonic mean of precision and recall. Facilitates analyzing the tradeoff between these metrics.\n",
    "\n",
    "**Coefficient of Variation (CV)** : Intra-cluster similarity to measure the accuracy of unsupervised classification models based on clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
